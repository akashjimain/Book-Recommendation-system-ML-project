{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "PoPl-ycgm1ru",
        "HaKxME6UIWET",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashjimain/Book-Recommendation-system-ML-project/blob/main/Book_Recommendation_System_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Unsupervised ML - Book Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Unsupervised ML\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Akash Tiwari\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Developed a book recommendation system for Amazon customers using memory and model based collaborative filtering by utilizing the description of book consumed and user interests. A recommendation engine is a class of machine learning which offers relevant suggestions to the customer. Before the recommendation system, the major tendency to buy was to take a suggestion from friends. But Now Google knows what news you will read, Youtube knows what type of videos you will watch based on your search history, watch history, or purchase history.\n",
        "\n",
        "A recommendation system helps an organization to create loyal customers and build trust by them desired products and services for which they came on your site. The recommendation system today are so powerful that they can handle the new customer too who has visited the site for the first time. They recommend the products which are currently trending or highly rated and they can also recommend the products which bring maximum profit to the company."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries).\n",
        "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. The main objective is to create a book recommendation system for users."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "# This is to supress the warning messages (if any) generated in our code\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading\n",
        "\n",
        "The Book-Crossing dataset comprises 3 files.\n",
        "* Users :\n",
        "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL values.\n",
        "\n",
        "*  Books :\n",
        "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in the case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavors (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon website.\n",
        "\n",
        "*  Ratings :\n",
        "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Users Data\n",
        "file_path = ('/content/drive/MyDrive/Users.csv')\n",
        "users = pd.read_csv(file_path)\n",
        "users.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Books data\n",
        "file_path = ('/content/drive/MyDrive/Books.csv')\n",
        "books = pd.read_csv(file_path)\n",
        "books.head()"
      ],
      "metadata": {
        "id": "qJYyjEUuBQVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratings Data\n",
        "file_path = ('/content/drive/MyDrive/Ratings.csv')\n",
        "ratings = pd.read_csv(file_path)\n",
        "ratings.head()"
      ],
      "metadata": {
        "id": "pFQACv-JBcWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'''\\t  Book_df shape is {books.shape}\n",
        "          Ratings_df shape is {ratings.shape}\n",
        "          Users_df shape is {users.shape}''')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Users Dataset"
      ],
      "metadata": {
        "id": "GKiPvK9Jc4I_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values\n",
        "def missing_values(df):\n",
        "    mis_val=df.isnull().sum()\n",
        "    mis_val_percent=round(df.isnull().mean().mul(100),2)\n",
        "    mz_table=pd.concat([mis_val,mis_val_percent],axis=1)\n",
        "    mz_table=mz_table.rename(\n",
        "    columns={df.index.name:'col_name',0:'Missing Values',1:'% of Total Values'})\n",
        "    mz_table['Data_type']=df.dtypes\n",
        "    mz_table=mz_table.sort_values('% of Total Values',ascending=False)\n",
        "    return mz_table.reset_index()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(users)"
      ],
      "metadata": {
        "id": "4T8REKqnGUhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age have around 39% missing values.**"
      ],
      "metadata": {
        "id": "sccWaBe4G_Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno\n",
        "msno.matrix(users)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Age Distribution"
      ],
      "metadata": {
        "id": "_kCmt3q-HkFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram for age distribution\n",
        "users.Age.hist(bins=[0, 10, 20, 30, 40, 50, 100])\n",
        "plt.title('Age Distribution\\n')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wDQ6xfFqHqJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The most active users are among those in their 20–30s.**"
      ],
      "metadata": {
        "id": "9DrJpLSjIKRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's check for outliers in age column"
      ],
      "metadata": {
        "id": "HaKxME6UIWET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(y='Age', data=users)\n",
        "plt.title('Find outlier data in Age column')"
      ],
      "metadata": {
        "id": "AdcjzJUHIYjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For unique value in age column\n",
        "print(sorted(users.Age.unique()))"
      ],
      "metadata": {
        "id": "eMoCl1vgIrRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age : 244\n",
        "we have Outlier data in Age**"
      ],
      "metadata": {
        "id": "OlA19TiVI6Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For unique value in location column\n",
        "users.Location.unique()"
      ],
      "metadata": {
        "id": "cprK2ftAJPeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count no of unique value in location\n",
        "users.Location.nunique()"
      ],
      "metadata": {
        "id": "qAwk8XMBJYss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "57339 unique Value it's really hard to understand"
      ],
      "metadata": {
        "id": "inVcmcoSJybT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lets create column Country"
      ],
      "metadata": {
        "id": "7mg01cgPJ44l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in users:\n",
        "    users['Country']=users.Location.str.extract(r'\\,+\\s?(\\w*\\s?\\w*)\\\"*$')"
      ],
      "metadata": {
        "id": "4ALHBPGaJ-VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.Country.nunique()"
      ],
      "metadata": {
        "id": "5b-H346NKC8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop location column\n",
        "users.drop('Location',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "CPtwwVeAKKFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head(2)"
      ],
      "metadata": {
        "id": "2CrqQRh0Khx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values\n",
        "users.isnull().sum()"
      ],
      "metadata": {
        "id": "BA-Ci2jIKnNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users['Country']=users['Country'].astype('str')"
      ],
      "metadata": {
        "id": "ZVRNgtr9Kymw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=list(users.Country.unique())\n",
        "a=set(a)\n",
        "a=list(a)\n",
        "a = [x for x in a if x is not None]\n",
        "a.sort()\n",
        "print(a)"
      ],
      "metadata": {
        "id": "nxE5_O1xK4Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08pPo0YCHoT-"
      },
      "source": [
        "# Some data has Misspellings Let's correct it\n",
        "\n",
        "users['Country'].replace(['','01776','02458','19104','23232','30064','85021','87510','alachua','america','austria','autralia','cananda','geermany','italia','united kindgonm','united sates','united staes','united state','united states','us'],\n",
        "                           ['other','usa','usa','usa','usa','usa','usa','usa','usa','usa','australia','australia','canada','germany','italy','united kingdom','usa','usa','usa','usa','usa'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Country',data=users,palette=['#432371',\"#9b59b6\", \"#3498db\",\"#fc9272\",\"#fee0d2\",\"#FAAE7B\",\"#4498dc\",\"#fd9278\",\"#fec0d4\",\"#FBAE7C\"],order=pd.value_counts(users['Country']).iloc[:10].index)\n",
        "plt.title('Count of users Country wise')"
      ],
      "metadata": {
        "id": "UVZEDXaKLURY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most number of users are from USA**"
      ],
      "metadata": {
        "id": "OERkGUvCZgJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's treat outliers in users age"
      ],
      "metadata": {
        "id": "0UgQ5fiAZm31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(users.Age)\n",
        "plt.title('Age Distribution Plot')"
      ],
      "metadata": {
        "id": "Dd_XF-jTZt8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age value's below 5 and above 100 do not make much sense for our book rating case...hence replacing these by NaNs**"
      ],
      "metadata": {
        "id": "iOiKO83Pa2Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier data became NaN\n",
        "users.loc[(users.Age > 100) | (users.Age < 5), 'Age'] = np.nan"
      ],
      "metadata": {
        "id": "89z9i8o3bAHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "I0E4jAcdbGG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Age has positive Skewness (right tail) so we can use median to fill Nan values, but for this we don't like to fill Nan value just for one range of age. To handle this we'll use country column to fill Nan.**"
      ],
      "metadata": {
        "id": "rNs1UhKRbN0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users['Age'] = users['Age'].fillna(users.groupby('Country')['Age'].transform('median'))"
      ],
      "metadata": {
        "id": "TbQY_sHpbQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "0Bd4fhIqbaEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still we have 276 Nan values let's fill them with mean"
      ],
      "metadata": {
        "id": "8fNPHa90bgBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users['Age'].fillna(users.Age.mean(),inplace=True)"
      ],
      "metadata": {
        "id": "S9tQSzqQbhMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "X0Uy1lhVbnnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Books Dataset"
      ],
      "metadata": {
        "id": "_wYDY3Fnb9Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.head(2)"
      ],
      "metadata": {
        "id": "KtHpq9yocDq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 Authors which have written the most books\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Book-Author',data=books,order=pd.value_counts(books['Book-Author']).iloc[:10].index)\n",
        "plt.title('Top 10 Authors')"
      ],
      "metadata": {
        "id": "XBYh5--ocLVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 Publisher which have published the most books.\n",
        "plt.figure(figsize=(15,7))\n",
        "sns.countplot(y='Publisher',data=books,order=pd.value_counts(books['Publisher']).iloc[:10].index)\n",
        "plt.title('Top 10 Publishers')"
      ],
      "metadata": {
        "id": "ao3e3YhpcWJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books['Year-Of-Publication']=books['Year-Of-Publication'].astype('str')\n",
        "a=list(books['Year-Of-Publication'].unique())\n",
        "a=set(a)\n",
        "a=list(a)\n",
        "a = [x for x in a if x is not None]\n",
        "a.sort()\n",
        "print(a)"
      ],
      "metadata": {
        "id": "J4PkXcnVcjkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#investigating the rows having 'DK Publishing Inc' as yearOfPublication\n",
        "books.loc[books['Year-Of-Publication'] == 'DK Publishing Inc',:]"
      ],
      "metadata": {
        "id": "D77PZKwjcpOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As it can be seen from above that there are some incorrect entries in Year-Of-Publication field. It looks like Publisher names 'DK Publishing Inc' and 'Gallimard' have been incorrectly loaded as\n",
        "# Year-Of-Publication in dataset due to some errors in csv file\n",
        "#From above, it is seen that bookAuthor is incorrectly loaded with bookTitle, hence making required corrections\n",
        "#ISBN '0789466953'\n",
        "books.loc[books.ISBN == '0789466953','Year-Of-Publication'] = 2000\n",
        "books.loc[books.ISBN == '0789466953','Book-Author'] = \"James Buckley\"\n",
        "books.loc[books.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '0789466953','Book-Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\"\n",
        "\n",
        "#ISBN '078946697X'\n",
        "books.loc[books.ISBN == '078946697X','Year-Of-Publication'] = 2000\n",
        "books.loc[books.ISBN == '078946697X','Book-Author'] = \"Michael Teitelbaum\"\n",
        "books.loc[books.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
        "books.loc[books.ISBN == '078946697X','Book-Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\"\n",
        "\n",
        "#rechecking\n",
        "books.loc[(books.ISBN == '0789466953') | (books.ISBN == '078946697X'),:]\n",
        "#corrections done"
      ],
      "metadata": {
        "id": "pekyRKUlc4Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#investigating the rows having 'Gallimard' as yearOfPublication\n",
        "books.loc[books['Year-Of-Publication'] == 'Gallimard',:]"
      ],
      "metadata": {
        "id": "TRPfGgo4dKyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making required corrections as above, keeping other fields intact\n",
        "books.loc[books.ISBN == '2070426769','Year-Of-Publication'] = 2003\n",
        "books.loc[books.ISBN == '2070426769','Book-Author'] = \"Jean-Marie Gustave Le ClÃ?Â©zio\"\n",
        "books.loc[books.ISBN == '2070426769','Publisher'] = \"Gallimard\"\n",
        "books.loc[books.ISBN == '2070426769','Book-Title'] = \"Peuple du ciel, suivi de 'Les Bergers\"\n",
        "\n",
        "\n",
        "books.loc[books.ISBN == '2070426769',:]"
      ],
      "metadata": {
        "id": "_2sCFET8dQuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books['Year-Of-Publication']=pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
        "\n",
        "print(sorted(books['Year-Of-Publication'].unique()))\n",
        "#Now it can be seen that yearOfPublication has all values as integers"
      ],
      "metadata": {
        "id": "n5bENCs2dYCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value 0 for Year-Of_Publication is invalid and as this dataset was published in 2004, We have assumed that the years after 2006 to be invalid and setting invalid years as NaN"
      ],
      "metadata": {
        "id": "0D8C_vSvdfrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.loc[(books['Year-Of-Publication'] > 2006) | (books['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "\n",
        "#replacing NaNs with median value of Year-Of-Publication\n",
        "books['Year-Of-Publication'].fillna(round(books['Year-Of-Publication'].median()), inplace=True)"
      ],
      "metadata": {
        "id": "WkMu8QzQdmW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping last three columns containing image URLs which will not be required for analysis\n",
        "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "CtkqkSUJdti1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.isna().sum()"
      ],
      "metadata": {
        "id": "ICn_ALRZd0YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring 'publisher' column\n",
        "books.loc[books.Publisher.isnull(),:]\n",
        "#two NaNs"
      ],
      "metadata": {
        "id": "8BvaWL8Gd726"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling Nan of Publisher with others\n",
        "books.Publisher.fillna('other',inplace=True)"
      ],
      "metadata": {
        "id": "k2TjeAcveA0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploring 'Book-Author' column\n",
        "books.loc[books['Book-Author'].isnull(),:]"
      ],
      "metadata": {
        "id": "VgG-ZLjseCrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling Nan of Book-Author with others\n",
        "books['Book-Author'].fillna('other',inplace=True)"
      ],
      "metadata": {
        "id": "offIpysIeKCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.isna().sum()"
      ],
      "metadata": {
        "id": "mXp6INVeeOpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ratings Dataset"
      ],
      "metadata": {
        "id": "-NANHQVqeWdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(5)\n",
        "\n",
        "# Ratings dataset should have books only which exist in our books dataset"
      ],
      "metadata": {
        "id": "xZWr0sYAecZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]\n",
        "ratings.shape,ratings_new.shape\n",
        "\n",
        "# It can be seen that many rows having book ISBN not part of books dataset got dropped off"
      ],
      "metadata": {
        "id": "cFcLUWuRepLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings dataset should have ratings from users which exist in users dataset.\n",
        "print(\"Shape of dataset before dropping\",ratings_new.shape)\n",
        "ratings_new = ratings_new[ratings_new['User-ID'].isin(users['User-ID'])]\n",
        "print(\"shape of dataset after dropping\",ratings_new.shape)\n",
        "\n",
        "# It can be seen that no new user was there in ratings dataset."
      ],
      "metadata": {
        "id": "4QtP44dae0WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how the ratings are distributed\n",
        "\n",
        "plt.rc(\"font\", size=15)\n",
        "ratings_new['Book-Rating'].value_counts(sort=False).plot(kind='bar')\n",
        "plt.title('Rating Distribution\\n')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-pNdFw1fS_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ratings are very unevenly distributed, and the vast majority of ratings are 0 .As quoted in the description of the dataset - BX-Book-Ratings contains the book rating information. Ratings are either explicit, expressed on a scale from 1-10 higher values denoting higher appreciation, or implicit, expressed by 0.Hence segragating implicit and explict ratings datasets.**"
      ],
      "metadata": {
        "id": "Xa8Ac-JvgQ1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hence segragating implicit and explict ratings datasets\n",
        "ratings_explicit = ratings_new[ratings_new['Book-Rating'] != 0]\n",
        "ratings_implicit = ratings_new[ratings_new['Book-Rating'] == 0]"
      ],
      "metadata": {
        "id": "B02YvClXgeFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ratings_explicit dataset shape',ratings_explicit.shape)\n",
        "print('ratings_implicit dataset',ratings_implicit.shape)"
      ],
      "metadata": {
        "id": "7ek1BEmCghe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(data=ratings_explicit , x='Book-Rating', palette='rocket_r')"
      ],
      "metadata": {
        "id": "2dKKUpp7gpcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It can be observe that higher ratings are more common amongst users and rating 8 has been rated highest number of times**\n",
        "\n"
      ],
      "metadata": {
        "id": "eLQ4ngyUg0nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's find the top 5 books which are rated by most number of users\n",
        "\n",
        "rating_count = pd.DataFrame(ratings_explicit.groupby('ISBN')['Book-Rating'].count())\n",
        "rating_count.sort_values('Book-Rating', ascending=False).head()\n",
        "\n",
        "# The book with ISBN '0316666343' received the most rating counts."
      ],
      "metadata": {
        "id": "bySHhR4qhDeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s find out what book it is, and what books are in the top 5.\n",
        "\n",
        "most_rated_books = pd.DataFrame(['0316666343', '0971880107', '0385504209', '0312195516', '0060928336'], index=np.arange(5), columns = ['ISBN'])\n",
        "most_rated_books_summary = pd.merge(most_rated_books, books, on='ISBN')\n",
        "most_rated_books_summary"
      ],
      "metadata": {
        "id": "ZLm3chdxhWKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The book that received the most rating counts in this data set is Rich Shapero’s “Wild Animus”. And there is something in common among these five books that received the most rating counts — they are all novels. So it is conclusive that novels are popular and likely receive more ratings."
      ],
      "metadata": {
        "id": "GXkAo4T3hkyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create column Rating average\n",
        "ratings_explicit['Avg_Rating']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('mean')\n",
        "# Create column Rating sum\n",
        "ratings_explicit['Total_No_Of_Users_Rated']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
      ],
      "metadata": {
        "id": "rs8ViN3Cho5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.head()"
      ],
      "metadata": {
        "id": "DehsTkxVhtEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging All Dataset"
      ],
      "metadata": {
        "id": "Ns6dIMrdh515"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Dataset=users.copy()\n",
        "Final_Dataset=pd.merge(Final_Dataset,ratings_explicit,on='User-ID')\n",
        "Final_Dataset=pd.merge(Final_Dataset,books,on='ISBN')"
      ],
      "metadata": {
        "id": "zes4_LXph8QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Dataset.head()"
      ],
      "metadata": {
        "id": "oY79AsUViDWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding missing values\n",
        "\n",
        "missing_values(Final_Dataset)"
      ],
      "metadata": {
        "id": "dxOMKkT_iKVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final dataset dimension\n",
        "\n",
        "Final_Dataset.shape"
      ],
      "metadata": {
        "id": "5SXXPZy3iUu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Popularity Based Filtering**"
      ],
      "metadata": {
        "id": "Fo5kpsVzjGyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the name suggests Popularity based recommendation system works with the trend. It basically uses the items which are in trend right now. For example, if any book which is usually bought by every new user then there are chances that it may suggest that book to the user who just signed up.\n",
        "\n",
        "Book weighted avg formula:\n",
        "\n",
        "Weighted Rating(WR)=[vR/(v+m)]+[mC/(v+m)]\n",
        "\n",
        "where,\n",
        "\n",
        "v is the number of votes for the books;\n",
        "\n",
        "m is the minimum votes required to be listed in the chart;\n",
        "\n",
        "R is the average rating of the book; and\n",
        "\n",
        "C is the mean vote across the whole report.\n",
        "\n",
        "Now we find the values of v,m,R,C."
      ],
      "metadata": {
        "id": "0OLT8KOMjT0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C= Final_Dataset['Avg_Rating'].mean()\n",
        "m= Final_Dataset['Total_No_Of_Users_Rated'].quantile(0.90)\n",
        "Top_Books = Final_Dataset.loc[Final_Dataset['Total_No_Of_Users_Rated'] >= m]\n",
        "print(f'C={C} , m={m}')\n",
        "Top_Books.shape"
      ],
      "metadata": {
        "id": "Rr7O3qggjoj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used 90th percentile as our cutoff. In other words, for a book to feature in the charts, it must have more votes than at least 90% of the books in the list.\n",
        "\n",
        "We see that there are 38570 books which qualify to be in this list. Now, we need to calculate our metric for each qualified book. To do this, we will define a function, weighted_rating() and define a new feature score, of which we’ll calculate the value by applying this function to our DataFrame of qualified books:"
      ],
      "metadata": {
        "id": "YQou8mS0juTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rating(x, m=m, C=C):\n",
        "    v = x['Total_No_Of_Users_Rated']\n",
        "    R = x['Avg_Rating']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
        "\n",
        "\n",
        "Top_Books['Score'] = Top_Books.apply(weighted_rating,axis=1)\n",
        "\n",
        "\n",
        "#Sorting books based on score calculated above\n",
        "Top_Books = Top_Books.sort_values('Score', ascending=False)"
      ],
      "metadata": {
        "id": "IbZ9v2pVj1EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keeping only one entry of each book\n",
        "Top_Books=Top_Books.sort_values('Score', ascending=False).drop_duplicates('ISBN').sort_index()\n",
        "cm=sns.light_palette('yellow',as_cmap=True)\n",
        "#Sorting books based on score calculated above\n",
        "Top_Books = Top_Books.sort_values('Score', ascending=False)\n",
        "\n",
        "#Printing the top 20 books\n",
        "Top_Books[['Book-Title', 'Total_No_Of_Users_Rated', 'Avg_Rating', 'Score']].reset_index(drop=True).head(20).style.background_gradient(cmap=cm)"
      ],
      "metadata": {
        "id": "C2cdFycuj264"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The Popularity based recommender provide a general chart of recommended books to all the users. They are not sensitive to the interests and tastes of a particular user.**"
      ],
      "metadata": {
        "id": "4qXH-iinj8Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Based Collaborative Filtering Recommender\n",
        "\n",
        "Model-based recommendation is a type of recommendation system that relies on building a predictive model based on the user-item interactions or other relevant features present in the dataset. Unlike memory-based collaborative filtering techniques that directly use the user-item interactions, model-based approaches create a model to predict user preferences and provide recommendations based on this model.\n",
        "\n",
        "The goal of the recommender system is to predict user preference for a set of items based on the past experience. Two the most popular approaches are Content-Based and Collaborative Filtering.\n",
        "\n",
        "Collaborative filtering is a technique used by websites like Amazon, YouTube, and Netflix. It filters out items that a user might like on the basis of reactions of similar users. There are two categories of collaborative filtering algorithms: memory based and model based.\n",
        "\n",
        "Model based approach involves building machine learning algorithms to predict user's ratings. They involve dimensionality reduction methods that reduce high dimensional matrix containing abundant number of missing values with a much smaller matrix in lower-dimensional space.\n",
        "\n",
        "The goal of this section is to compare SVD and NMF algorithms, try different configurations of parameters and explore obtained results.\n",
        "\n"
      ],
      "metadata": {
        "id": "r_whdBYpkQ9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing liberaries\n",
        "\n",
        "import scipy\n",
        "import math\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KDW8DPy3kiqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This analysis will focus on book recommendations based on Book-Crossing dataset. To reduce the dimensionality of the dataset and avoid running into memory error we will focus on users with at least 3 ratings and top 10% most frequently rated books.\n",
        "The recommender systems will be built using surprise package (Matrix Factorization - based models)."
      ],
      "metadata": {
        "id": "_Hw34CKikvi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.rename(columns = {'User-ID':'user_id' ,'ISBN':'isbn' ,'Book-Rating':'book_rating'},inplace=True)"
      ],
      "metadata": {
        "id": "rEzWIhWWk2vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ratings_threshold = 3\n",
        "\n",
        "filter_users = ratings_explicit['user_id'].value_counts()\n",
        "filter_users_list = filter_users[filter_users >= user_ratings_threshold].index.to_list()\n",
        "\n",
        "df_ratings_top = ratings_explicit[ratings_explicit['user_id'].isin(filter_users_list)]\n",
        "\n",
        "print('Filter: users with at least %d ratings\\nNumber of records: %d' % (user_ratings_threshold, len(df_ratings_top)))"
      ],
      "metadata": {
        "id": "WdFonoskk_VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratings_threshold_perc = 0.1\n",
        "book_ratings_threshold = len(df_ratings_top['isbn'].unique()) * book_ratings_threshold_perc\n",
        "\n",
        "filter_books_list = df_ratings_top['isbn'].value_counts().head(int(book_ratings_threshold)).index.to_list()\n",
        "df_ratings_top = df_ratings_top[df_ratings_top['isbn'].isin(filter_books_list)]\n",
        "\n",
        "print('Filter: top %d%% most frequently rated books\\nNumber of records: %d' % (book_ratings_threshold_perc*100, len(df_ratings_top)))"
      ],
      "metadata": {
        "id": "sGk0pskTlDoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVD and NMF models comparisonSingular Value Decomposition (SVD) and Non-negative Matrix Factorization (NMF) are matrix factorization techniques used for dimensionality reduction. Surprise package provides implementation of those algorithms."
      ],
      "metadata": {
        "id": "a85lv7wllLii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "id": "4_CAhELslUii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader\n",
        "from surprise import SVD, NMF\n",
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "zmukexnxlqEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_ratings_top.copy()\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "data = Dataset.load_from_df(df[['user_id', 'isbn', 'book_rating']], reader)"
      ],
      "metadata": {
        "id": "yJaaheeilr2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_svd = SVD()\n",
        "cv_results_svd = cross_validate(model_svd, data, cv=3)\n",
        "pd.DataFrame(cv_results_svd).mean()"
      ],
      "metadata": {
        "id": "aFnEfCANlw0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nmf = NMF()\n",
        "cv_results_nmf = cross_validate(model_nmf, data, cv=3)\n",
        "pd.DataFrame(cv_results_nmf).mean()"
      ],
      "metadata": {
        "id": "5CGpEDLFl4M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's clear that for the given dataset much better results can be obtained with SVD approach - both in terms of accuracy and training / testing time.**"
      ],
      "metadata": {
        "id": "eX2D1MXBl-jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimisation of SVD algorithm\n",
        "\n",
        "Grid Search Cross Validation computes accuracy metrics for an algorithm on various combinations of parameters, over a cross-validation procedure. It's useful for finding the best configuration of parameters.\n",
        "\n",
        "It is used to find the best setting of parameters:\n",
        "\n",
        "n_factors - the number of factors\n",
        "\n",
        "n_epochs - the number of iteration of the SGD procedure\n",
        "\n",
        "lr_all - the learning rate for all parameters\n",
        "\n",
        "reg_all - the regularization term for all parameters\n",
        "\n",
        "As a result, regarding the majority of parameters, the default setting is the most optimal one. The improvement obtained with Grid Search is very small."
      ],
      "metadata": {
        "id": "BEpgtNqymKjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_factors': [80,100],\n",
        "              'n_epochs': [5, 20],\n",
        "              'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.2, 0.4]}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "WAS_RR0btq0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Collaborative Filtering model results\n",
        "\n",
        "In this part, let's examine in detail the results obtained by the SVD model that provided the best RMSE score."
      ],
      "metadata": {
        "id": "wohiSjJ4t6Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "model = SVD(n_factors=80, n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
        "model.fit(trainset)\n",
        "predictions = model.test(testset)"
      ],
      "metadata": {
        "id": "AynqGsbmuQ1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.DataFrame(predictions, columns=['user_id', 'isbn', 'actual_rating', 'pred_rating', 'details'])\n",
        "df_pred['impossible'] = df_pred['details'].apply(lambda x: x['was_impossible'])\n",
        "df_pred['pred_rating_round'] = df_pred['pred_rating'].round()\n",
        "df_pred['abs_err'] = abs(df_pred['pred_rating'] - df_pred['actual_rating'])\n",
        "df_pred.drop(['details'], axis=1, inplace=True)\n",
        "df_pred.sample(5)"
      ],
      "metadata": {
        "id": "xUwRa0JQuVeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of actual and predicted ratings in the test set According to the distribution of actual ratings of books in the test set, the biggest part of users give positive scores - between 7 and 10. The mode equals 8 but count of ratings 7, 9, 10 is also noticeable. The distribution of predicted ratings in the test set is visibly different. One more time, 8 is a mode but scores 7, 9 and 10 are clearly less frequent.\n",
        "It shows that the recommender system is not perfect and it cannot reflect the real distribution of book ratings."
      ],
      "metadata": {
        "id": "KqMLiVswucny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palette = sns.color_palette(\"RdBu\", 10)\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 4))\n",
        "\n",
        "sns.countplot(x='actual_rating', data=df_pred, palette=palette, ax=ax1)\n",
        "ax1.set_title('Distribution of actual ratings of books in the test set')\n",
        "\n",
        "sns.countplot(x='pred_rating_round', data=df_pred, palette=palette, ax=ax2)\n",
        "ax2.set_title('Distribution of predicted ratings of books in the test set')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aVwvpP0nuhwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Absolute error of predicted ratings\n",
        "The distribution of absolute errors is right-skewed, showing that the majority of errors is small: between 0 and 1. There is a long tail that indicates that there are several observations for which the absolute error was close to 10.\n",
        "How good/bad the model is with predicting certain scores? As expected from the above charts, the model deals very well with predicting score = 8 (the most frequent value). The further the rating from score = 8, the higher the absolute error. The biggest errors happen to observations with scores 1 or 2 which indicates that probably the model is predicting high ratings for those observations."
      ],
      "metadata": {
        "id": "4fTuyIh0upHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_err = df_pred.groupby('actual_rating')['abs_err'].mean().reset_index()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 4))\n",
        "\n",
        "sns.distplot(df_pred['abs_err'], color='#2f6194', ax=ax1)\n",
        "ax1.set_title('Distribution of absolute error in test set')\n",
        "\n",
        "sns.barplot(x='actual_rating', y='abs_err', data=df_pred_err, palette=palette, ax=ax2)\n",
        "ax2.set_title('Mean absolute error for rating in test set')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m3CFlpVRurPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of predicted ratings of a particular user\n",
        "For this part of the analysis, the user with id 193458 was selected. By analyzing book ratings by this user, it can be noted that he/she likes diverse types of readings: English romantic novels (Pride and Prejudice, Sense and Sensibility), fantasy (Narnia) as well as historical novels (Schindler's List). Among the recommended books there are other works from Narnia's series, two historical novels and one romance which correlates with user's previous preferences."
      ],
      "metadata": {
        "id": "rM2TRTZVu0ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books = books.copy()\n",
        "df_books.rename(columns = {'ISBN':'isbn' ,'Book-Title':'book_title'},inplace=True)\n",
        "df_ext = df.merge(df_books[['isbn', 'book_title']], on='isbn', how='left')\n",
        "df_ext = df_ext.merge(df_pred[['isbn', 'user_id', 'pred_rating']], on=['isbn', 'user_id'], how='left')"
      ],
      "metadata": {
        "id": "xaKehy7Lu3Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train set: Top rated books"
      ],
      "metadata": {
        "id": "8PfQm7kyu8LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_user_id = 193458\n",
        "df_user = df_ext[df_ext['user_id']==selected_user_id]\n",
        "\n",
        "df_user[(df_user['pred_rating'].isna())&(df_user['book_rating']>=9)].sample(10)"
      ],
      "metadata": {
        "id": "J0Db6CaYu9_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set: predicted top rated books"
      ],
      "metadata": {
        "id": "oAD1n8f1vCrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user[df_user['pred_rating'].notna()].sort_values('pred_rating', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "zC1HTz4IvGl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test set: actual top rated books"
      ],
      "metadata": {
        "id": "3_dkZ_kOvOUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_user[df_user['pred_rating'].notna()].sort_values('book_rating', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "26QuMAoSvPzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering based Recommendation System--(Item-Item Based)"
      ],
      "metadata": {
        "id": "T8qfrMcxvXVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing important liberaries\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial.distance import correlation\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from contextlib import contextmanager\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import re\n",
        "from scipy.sparse import csr_matrix"
      ],
      "metadata": {
        "id": "yVWkHVKRvdWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.head()"
      ],
      "metadata": {
        "id": "IGRJ2AjMwGdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.rename(columns={'user_id':'userID' ,'isbn':'ISBN','book_rating':'bookRating'},inplace=True)"
      ],
      "metadata": {
        "id": "0OKnATvJwM9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_top.head()"
      ],
      "metadata": {
        "id": "4QvxK2MnwM6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing KNN"
      ],
      "metadata": {
        "id": "YgbChOxewZ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating ratings matrix from explicit ratings table\n",
        "ratings_matrix = df_ratings_top.pivot(index='userID', columns='ISBN', values='bookRating')\n",
        "userID = ratings_matrix.index\n",
        "ISBN = ratings_matrix.columns\n",
        "print(ratings_matrix.shape)\n",
        "ratings_matrix.head()\n",
        "#Notice that most of the values are NaN (undefined) implying absence of ratings"
      ],
      "metadata": {
        "id": "n7p8TwOewbWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_users = ratings_matrix.shape[0] #considering only those users who gave explicit ratings\n",
        "n_books = ratings_matrix.shape[1]\n",
        "print (n_users, n_books)"
      ],
      "metadata": {
        "id": "OGCHB7xZwhv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_matrix.fillna(0, inplace = True)\n",
        "ratings_matrix = ratings_matrix.astype(np.int32)"
      ],
      "metadata": {
        "id": "aw8m9V0rwl9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking first few rows\n",
        "ratings_matrix.head(5)"
      ],
      "metadata": {
        "id": "u4837A5HwrYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = 1.0-len(ratings_explicit)/float(ratings_explicit.shape[0]*n_books)\n",
        "print ('The sparsity level of Book Crossing dataset is ' +  str(sparsity*100) + ' %')"
      ],
      "metadata": {
        "id": "0EUWXhWPwwhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_book_rating = pd.merge(ratings, books, on = 'ISBN')\n",
        "columns = ['Book-Author','Year-Of-Publication', 'Publisher']"
      ],
      "metadata": {
        "id": "5WbwyGzuwz7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "combine_book_rating = combine_book_rating.drop(columns, axis = 1)\n",
        "combine_book_rating.rename(columns={'User-ID':'userID','Book-Title':'bookTitle','Book-Rating':'bookRating'},inplace=True)\n",
        "combine_book_rating.head()"
      ],
      "metadata": {
        "id": "QmrTh7e2w3vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_book_rating = combine_book_rating.dropna(axis = 0, subset = ['bookTitle'])"
      ],
      "metadata": {
        "id": "BCXmXiQow8f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratingcount = (combine_book_rating.\n",
        "                    groupby(by = ['bookTitle',])['bookRating'].\n",
        "                    count().\n",
        "                    reset_index().\n",
        "                    rename(columns = {'bookRating':'TotalRatingCount'})\n",
        "                    [['bookTitle','TotalRatingCount']])"
      ],
      "metadata": {
        "id": "L0VbBzfCw_C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ratingcount.head()"
      ],
      "metadata": {
        "id": "aWvL6vrExLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the rating data with the total rating count data, this gives us exactly what we need to filter out the lesser known books\n",
        "\n",
        "rating_with_totalratingcount = combine_book_rating.merge(book_ratingcount, left_on = 'bookTitle', right_on = 'bookTitle', how = 'inner' )\n",
        "\n",
        "rating_with_totalratingcount.head()"
      ],
      "metadata": {
        "id": "VONKnQ40xUH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "print(book_ratingcount['TotalRatingCount'].describe())"
      ],
      "metadata": {
        "id": "5CLxSMLYxfYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median book has been rated only once. Let’s look at the top of the distribution:"
      ],
      "metadata": {
        "id": "Uy83hVcGxo35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(book_ratingcount['TotalRatingCount'].quantile(np.arange(.9,1,.01)))"
      ],
      "metadata": {
        "id": "N6tjUsZMxp2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 1% of the books received 50 or more ratings. Because we have so many books in our data, we will limit it to the top 1%"
      ],
      "metadata": {
        "id": "Cgj8vs8QxzWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popularity_threshold = 50\n",
        "rating_popular_book = rating_with_totalratingcount.query('TotalRatingCount >= @popularity_threshold')\n",
        "rating_popular_book.head()"
      ],
      "metadata": {
        "id": "JWyZmfwvx0U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not rating_popular_book[rating_popular_book.duplicated(['userID', 'bookTitle'])].empty:\n",
        "    initial_rows = rating_popular_book.shape[0]\n",
        "\n",
        "    print('Initial dataframe shape {0}'.format(rating_popular_book.shape))\n",
        "    rating_popular_book = rating_popular_book.drop_duplicates(['userID', 'bookTitle'])\n",
        "    current_rows = rating_popular_book.shape[0]\n",
        "    print('New dataframe shape {0}'.format(rating_popular_book.shape))\n",
        "    print('Removed {0} rows'.format(initial_rows - current_rows))"
      ],
      "metadata": {
        "id": "o9_ZujZuyAfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot = rating_popular_book.pivot(index = 'bookTitle',columns = 'userID', values = 'bookRating').fillna(0)\n",
        "us_canada_user_rating_matrix = csr_matrix(us_canada_user_rating_pivot.values)"
      ],
      "metadata": {
        "id": "saxXVsJ_yF13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding the Nearest Neighbors"
      ],
      "metadata": {
        "id": "Nvrv4w73yV1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "model_knn.fit(us_canada_user_rating_matrix)"
      ],
      "metadata": {
        "id": "twB0yG0WyXiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test our model and Make few Recommnedations"
      ],
      "metadata": {
        "id": "l2lNukAZyfmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_index = np.random.choice(us_canada_user_rating_pivot.shape[0])\n",
        "distances, indices = model_knn.kneighbors(us_canada_user_rating_pivot.iloc[query_index, :].values.reshape((1, -1)), n_neighbors = 6)\n",
        "\n",
        "for i in range(0, len(distances.flatten())):\n",
        "    if i == 0:\n",
        "        print('Recommendations for {0}:\\n'.format(us_canada_user_rating_pivot.index[query_index]))\n",
        "    else:\n",
        "        print('{0}: {1}, with distance of {2}:'.format(i, us_canada_user_rating_pivot.index[indices.flatten()[i]], distances.flatten()[i]))"
      ],
      "metadata": {
        "id": "1cYrlgs5yhR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot2 = rating_popular_book.pivot(index = 'userID', columns = 'bookTitle', values = 'bookRating').fillna(0)\n",
        "\n",
        "us_canada_user_rating_pivot2.head()"
      ],
      "metadata": {
        "id": "wmfg5V_fyoHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_user_rating_pivot2.shape"
      ],
      "metadata": {
        "id": "41ipzYutywdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = us_canada_user_rating_pivot2.values.T\n",
        "X.shape"
      ],
      "metadata": {
        "id": "SWby8lt1y0a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "SVD = TruncatedSVD(n_components=12, random_state=17)\n",
        "matrix = SVD.fit_transform(X)\n",
        "matrix.shape"
      ],
      "metadata": {
        "id": "IiGNTIRCy4Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = np.corrcoef(matrix)\n",
        "corr.shape"
      ],
      "metadata": {
        "id": "JuSBjkp8y8q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's find books similar to Harry Potter and the Sorcerer's Stone (Book 1)"
      ],
      "metadata": {
        "id": "65w0sY5wzA32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "us_canada_book_title = us_canada_user_rating_pivot2.columns\n",
        "us_canada_book_list = list(us_canada_book_title)\n",
        "coffey_hands = us_canada_book_list.index(\"Harry Potter and the Sorcerer's Stone (Book 1)\")"
      ],
      "metadata": {
        "id": "nk7ycmrPzC_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_coffey_hands  = corr[coffey_hands]\n",
        "\n",
        "list(us_canada_book_title[(corr_coffey_hands<1.0) & (corr_coffey_hands>0.9)])"
      ],
      "metadata": {
        "id": "_g_5AEwSzMhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collaborative Filtering based Recommendation System--(User-Item based)"
      ],
      "metadata": {
        "id": "H-YUMtZTzaZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_explicit.head()\n",
        "ratings_explicit.rename(columns={'user_id':'User-ID','isbn':'ISBN','book_rating':'Book-Rating'},inplace=True)\n",
        "\n",
        "ratings_explicit.head()"
      ],
      "metadata": {
        "id": "0fSWYC6RzegU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "users_interactions_count_df = ratings_explicit.groupby(['ISBN', 'User-ID']).size().groupby('User-ID').size()\n",
        "print('# of users: %d' % len(users_interactions_count_df))\n",
        "\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 100].reset_index()[['User-ID']]\n",
        "print('# of users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
      ],
      "metadata": {
        "id": "vt3u9Qimzzvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('# of interactions: %d' % len(ratings_explicit))\n",
        "interactions_from_selected_users_df = ratings_explicit.merge(users_with_enough_interactions_df,\n",
        "               how = 'right',\n",
        "               left_on = 'User-ID',\n",
        "               right_on = 'User-ID')\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
      ],
      "metadata": {
        "id": "_W5LXlcwz66D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_from_selected_users_df.head(10)"
      ],
      "metadata": {
        "id": "1TO7lZmXz8ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "\n",
        "interactions_full_df = interactions_from_selected_users_df.groupby(['ISBN', 'User-ID'])['Book-Rating'].sum().apply(smooth_user_preference).reset_index()\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
        "interactions_full_df.head()"
      ],
      "metadata": {
        "id": "6je8QxNR0FWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
        "                                   stratify=interactions_full_df['User-ID'],\n",
        "                                   test_size=0.20,\n",
        "                                   random_state=42)\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))"
      ],
      "metadata": {
        "id": "cjYpPHg-0Nka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_test_df.head()"
      ],
      "metadata": {
        "id": "JrGxv3pP0T0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with users in rows and items in columns\n",
        "users_items_pivot_matrix_df = interactions_train_df.pivot(index='User-ID',\n",
        "                                                          columns='ISBN',\n",
        "                                                          values='Book-Rating').fillna(0)\n",
        "\n",
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "kLs7OrHY0Z_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix = users_items_pivot_matrix_df.values\n",
        "users_items_pivot_matrix[:10]"
      ],
      "metadata": {
        "id": "t7QXRhQ_0fQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_ids = list(users_items_pivot_matrix_df.index)\n",
        "users_ids[:10]"
      ],
      "metadata": {
        "id": "4uCrZTOd0iyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)\n",
        "\n",
        "users_items_pivot_matrix.shape"
      ],
      "metadata": {
        "id": "7Pucqu1k0mwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U.shape"
      ],
      "metadata": {
        "id": "4lT9U7od0xga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "metadata": {
        "id": "Q1JkVEpY0015"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vt.shape"
      ],
      "metadata": {
        "id": "R0cRiSgn02Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the factorization, we try to to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It was generated predictions for items the user have not yet interaction, which we will exploit for recommendations."
      ],
      "metadata": {
        "id": "TNU_nYal1Bka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "all_user_predicted_ratings"
      ],
      "metadata": {
        "id": "BGPRiwwB0_7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings.shape"
      ],
      "metadata": {
        "id": "WeCfdXCK1IRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=users_ids).transpose()\n",
        "cf_preds_df.head()"
      ],
      "metadata": {
        "id": "5xNT7hEB1L9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "metadata": {
        "id": "siS3rH6K1Q2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global books\n",
        "books.head()"
      ],
      "metadata": {
        "id": "v4DOb5cJ1UB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating content that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('recStrength', ascending = False).head(topn)\n",
        "        recommendations_df=recommendations_df.merge(books,on='ISBN',how='inner')\n",
        "        recommendations_df=recommendations_df[['ISBN','Book-Title','recStrength']]\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "\n",
        "\n",
        "cf_recommender_model = CFRecommender(cf_preds_df)\n",
        "\n",
        "#Indexing by personId to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('User-ID')\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('User-ID')\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('User-ID')\n",
        "\n",
        "def get_items_interacted(UserID, interactions_df):\n",
        "    interacted_items = interactions_df.loc[UserID]['ISBN']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n",
        "\n",
        "class ModelRecommender:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, UserID, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(UserID, interactions_full_indexed_df)\n",
        "        all_items = set(ratings_explicit['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),topn=10000000000)\n",
        "        print('Recommendation for User-ID = ',person_id)\n",
        "        print(person_recs_df.head(10))\n",
        "\n",
        "        # Function to evaluate the performance of model at overall level\n",
        "    def recommend_book(self, model ,userid):\n",
        "\n",
        "        person_metrics = self.evaluate_model_for_user(model, userid)\n",
        "        return\n",
        "\n",
        "model_recommender = ModelRecommender()"
      ],
      "metadata": {
        "id": "4HL4Mqg61cuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's recommend books to User-Id 69078 and see the results."
      ],
      "metadata": {
        "id": "GOthP4Gq1wg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(interactions_full_indexed_df.index.values))"
      ],
      "metadata": {
        "id": "m7Co_Oyb1x-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user=int(input(\"Enter User ID from above list for book recommendation  \"))\n",
        "model_recommender.recommend_book(cf_recommender_model,user)"
      ],
      "metadata": {
        "id": "40f09uU218AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "In Recommender Systems, there are a set metrics commonly used for evaluation. We choose to work with Top-N accuracy metrics, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted in test set.\n",
        "\n",
        "This evaluation method works as follows:\n",
        "* For each user\n",
        "  * For each item the user has interacted in test set\n",
        "    * Sample 100 other items the user has never interacted.\n",
        "    * Ask the recommender model to produce a ranked list of recommended items, from a set composed of one interacted item and the 100 non-interacted items\n",
        "    * Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
        "* Aggregate the global Top-N accuracy metrics"
      ],
      "metadata": {
        "id": "RKLQcIgi2Mo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, UserID, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(UserID, interactions_full_indexed_df)\n",
        "        all_items = set(ratings_explicit['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, person_id):\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set([int(interacted_values_testset['ISBN'])])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, seed=item_id)    #%(2**32))\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        person_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return person_metrics\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
        "            person_metrics['User-ID'] = person_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('%d users processed' % idx)\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator()\n",
        "\n"
      ],
      "metadata": {
        "id": "p59rXpVv2vqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "\n",
        "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
        "cf_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "6Ld8QuN9Crt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In EDA, the Top-10 most rated books were essentially novels. Books like The Lovely Bone and The Secret Life of Bees were very well perceived.\n",
        "* Majority of the readers were of the age bracket 20-35 and most of them came from North American and European countries namely USA, Canada, UK, Germany and Spain.\n",
        "* If we look at the ratings distribution, most of the books have high ratings with maximum books being rated 8. Ratings below 5 are few in number.\n",
        "* Author with the most books was Agatha Christie, William Shakespeare and Stephen King.\n",
        "* For modelling, it was observed that for model based collaborative filtering SVD technique worked way better than NMF with lower Mean Absolute Error (MAE) .\n",
        "* Amongst the memory based approach, item-item CF performed better than user-user CF because of lower computation ."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}